"""dispersal

Model the settlement of the Americas using an agent-based model on a hex grid
with resource depletion, migration, and culture-dependent cooperation.

Model description following the ODD (Overview, Design concept, Details)
protocol (Grimm et al., 2006; Grimm et al., 2010) inline throughout the source
code of the model.

1. Purpose
==========

The settlement model generates a deep phylogeny of hunter-gatherer cultures
based on culture-mediated cooperation and resource-driven migration. The
summary statistics of this phylogeny (in particular diversification rates) are
to be compared to those known from language evolution. The model is structured
to be easily transferable to the history of the settlement of the Americas, but
requires paleoclimate data to produce results that can be compared to that
history.

"""
# General imports, which in Python should come on top of the module to make
# dependencies transparent.

import gavin2017processbased
import binford2001constructing
from util import *

# 2. Entities, state variables, and scales
# ========================================
@attr.s
class Patch:
    """A patch of land with resources

    Resources can vary through time, up to a fixed maximum
    """
    #NCP: this is a fixed maximum per cell, right? and it would be changeable based on palaeoclimatic data down the road?
    resources: kcal = attr.ib() # Resources available over a period of 6 months
    max_resources: kcal = attr.ib() # Maximum resources available over a period of 6 months
    # NCP: is there seasonality for the 6 month period? this is something that you would like to maybe add later?

@attr.s
class Cells():
    """A grid of cells

    By the default implementation in this module, every cell is a georeferenced
    hex cell in the Americas, each containing a Patch, representing an area of
    ca. 450_000_000 m²

    """
    patches: Mapping[Index, Patch] = attr.ib()

    # A grid knows its topology. The specific implementation is elsewhere.
    @abstractmethod
    def neighbors(self, i: Index) -> Sequence[Index]:
        raise NotImplementedError
    @abstractmethod
    def neighbors_within_distance(
            self,
            cell: Index,
            distance: meters) -> Iterable[Index]:
        raise NotImplementedError

# A culture is just a tuple with 7 different slots.
# NCP: what do these 7 different slots represent? or they are 7 arbitrary dimensions so that things get differentiated?
Culture = List[bool]

@attr.s
class Family:
    """A family group agent

    Families are the decision-making agent in our model. Families can migrate
    between cells and form links to other Families in the context of
    cooperation to extract or share resources.
    # NCP: a family can be in only one cell at a time

    """
    descendence: str = attr.ib()
    # The agent's history of decendence, also serving as unique ID
    culture: Culture = attr.ib()
    # The family's shared culture
    location_history: List[Index] = attr.ib(factory=list)
    # A list of cell indices.
    number_offspring: int = attr.ib(default=0)
    # The number of descendant families this family has given rise to so far
    effective_size: int = attr.ib(default=2)
    # The effective size of the family in number of adults. One adult is
    # assumed to consume the same amount of food/energy and to contribute the same labor to
    # foraging as any other adult.
    stored_resources: kcal = attr.ib(default=0)
    # The amount of stored resources, in kcal, the family has access to
    plenty_seasons_since_last_child: int = attr.ib(default=0)
    # The number of plentiful seasons since the birth of the previous child
    # NCP: plentiful as opposed to what? if they decide to migrate this is not a plentiful season?

    seasons_until_next_mutation: int = attr.ib(default=-1)
    # A bookkeeping quantity. Instead of mutation happening in each time step
    # with a tiny probability, the same distribution of times between mutations
    # is generated by drawing a number of season from a geometric distribution
    # and counting it down by one each time step.

@attr.s
class State:
    """A model state"""
    grid: Cells = attr.ib()
    # The state of cells at this time step
    # Keeping track of their locations locally is easier than looking for them post-hoc, even though it is redundant.
    # NCP: the locations of the cells, or the families? I don't get what the state of a cell is nor its location. I thought its location is fixed.
    families: Mapping[Index, List[Family]] = attr.ib()
    # A list of families under simulation
    t: halfyears = attr.ib(default=0)
    # Time steps since simulation start, in 1/2 of a year.

class CooperativeGroup(list):
    """A group of Families cooperating"""
    efficiency: float = attr.ib() # The group's efficiency at exploiting resources, between 0 and 1
    # NCP: how is the value determined? is it 1 always before the addition of culture and then it depends on some distance between cultures?

# 3. Process overview and scheduling
# ==================================
def step(state: State) -> State:
    """Run a simulation step."""

    for family in shuffle(sum(state.families.values(), [])):
        use_resources_and_maybe_shrink(family)
        maybe_grow(family)
        if is_moribund(family):
            state.families[family.location_history[0]].remove(family)
            continue
        descendant = maybe_procreate(family)
        if descendant is not None:
            # In terms of scheduling, this means in particular that a new
            # family can move immediately. This behaviour is taken from del
            # Castillo (2013). Also, a descendant family will move *before*
            # their progenitor.
            destination = decide_on_moving(
                descendant,
                state.grid.patches[family.location_history[0]],
                observe_neighbors(
                    family, state.grid.patches, state.families,
                    state.grid.neighbors_within_distance(family.location_history[0], meters(42413))))
            movement_bookkeeping(descendant, destination, state)
        # Earlier moves affect the possible targets of later moves,
        # so scheduling matters and shuffling is important to remove
        # first-mover effects.

        destination = decide_on_moving(
            family, state.grid.patches[family.location_history[0]],
            observe_neighbors(
                family, state.grid.patches, state.families,
                state.grid.neighbors_within_distance(family.location_history[0], meters(42413))))
        movement_bookkeeping(family, destination, state)

    for patch_id, families in state.families.items():
        if not families:
            continue
        for family in families:
            assert family.location_history[0] == patch_id
        patch = state.grid.patches[patch_id]
        resource_reduction = 0.0
        # For exploitation, all parts of it happen at the same time.
        # NCP: I don't understand exploitation here. I imagine it is a phase but it is not clear when it starts and ends
        groups_and_efficiencies, sum_labor = cooperate(families)
        for cooperating_families in groups_and_efficiencies:
            resource_reduction += extract_resources(patch, cooperating_families, sum_labor)
            adjust_culture(cooperating_families)

        exploit(patch, resource_reduction)

    for patch in state.grid.patches.values():
        recover(patch)

    observation(state)

    state.t += 1

    return state

def simulate(state: State, n_steps: int=15000 * 2) -> State:
    for t in range(n_steps):
        state = step(state)
    return state

"""
4. Design concepts
==================

This model draws heavily on two prior models.

4.1 Basic priciples
===================
 • Migration happens due to the need to find new resources in marginal environments
 • Shared culture mediates cooperation, and cooperation fosters cultural cohesion
 • Using real(istic) geography provides better insight than abstract environments
 • The family is generally the basic unit of decision-making and migration in
   hunter-gatherer societis

4.2 Emergence
=============

"""

params: Namespace


def plot_cultural_distance_by_geographical_distance(state: State) -> Tuple[Sequence, Sequence]:
    """Plot the cultural distance vs. geographical distance

    We expect that the interplay of migration, cooperation and cultural
    similarity leads to regions of similar cultures with steep geographical
    transition areas to regions containing agents with different culture
    vectors.

    This means that the plot of cultural distances vs. geographical distances
    should therefore show small cultural distances for small geographical
    distances. There should be a critical geographical distance of cohesion
    where the distribution of cultural distances becomes bimodal, with one mode
    being lower than the cooperation threshold and one mode above the
    cooperation threshold. For large geographical distances, the cultural
    distances should be high, but with a big variance.

    """
    cult_dists: List[float] = []
    geo_dists = []
    for (l1, fs1), (l2, fs2) in itertools.combinations_with_replacement(
            state.families.items(), 2):
        geo_dist = geographical_distance(l1, l2)
        for family1, family2 in itertools.product(fs1, fs2):
            cult_dist = cultural_distance(family1.culture, family2.culture)
            geo_dists.append(geo_dist); cult_dists.append(cult_dist)
    return geo_dists, cult_dists


"""
4.3 Adaptation
==============
 • The adaptive behaviour of agents is restricted to their movement, which is
   implemented to optimize resource availability in the upcoming time step.

4.4 Objectives
==============
 • Agents evaluate the expected resources they will be able to exploit in the
   current time step based on the resources available in patches within a
   certain distance from themselves, and the number of agents in each of those
   patches.
   # NCP: here it sounds like a family is able to exploit multiple patches. maybe add "in each patch" after exploit

4.5 Learning
============
 • Agents do not modify behaviour based on past experience.

4.6 Prediction
==============

 • Agents use the state of their neighborhood as a proxy for the future state of
   the system for predicting the expected number of resources available to them.
   Due to scheduling, this means that agents see on average half of the
   remaining agents in their new positions after moving and half of the
   remaining agents in their old position before moving. Agents extrapolate
   their resource availability with and without expending labour from the
   current state of the system, ie. without taking potential family growth or
   shrinking into account and without taking the movement of agents into
   account.
"""
# NCP: what is neighborhood? the patches around a family's patches? the ones they are able to observe?

def family_expects_current_patch_will_be_enough(family: Family, resource_gain: kcal) -> bool:
    return resources_at_season_end(
        family.stored_resources + resource_gain,
        family.effective_size) > 0
"""
4.7 Sensing
===========
 • Agents have access to the current state of their neighborhood (actual
   available resources and position, size and culture vectors of nearby agents)
   for the decision process whether and where to move.
"""

def observe_neighbors(
        family: Family,
        patches: Mapping[Index, Patch],
        all_families: Mapping[Index, Sequence[Family]],
        neighbors: Iterable[Index]) -> Iterator[
        Tuple[Index, Patch, int, int]]:
    checked = set()
    for dest in family.location_history[:4] + shuffle([
            n for n in neighbors
            if n in family.location_history[:8] or numpy.random.random() < params.attention_probability]):
        if dest in checked:
            continue
        checked.add(dest)
        if patches[dest].max_resources < 1:
            # Don't walk into the water
            continue
        cooperators, competitors = 0, 0
        for f in all_families[dest]:
            if cultural_distance(f.culture, family.culture) < params.cooperation_threshold:
                cooperators += f.effective_size
            else:
                competitors += f.effective_size
        yield dest, patches[dest], cooperators, competitors

# NCP: what is the cooperation threshold? 
"""
4.8 Interaction
===============
 • Agents compete for limited resources
 • Agents of similar culture cooperate in the exploitation of resources
"""

def cultural_distance(c1: Culture, c2: Culture) -> float:
    """ Cultural distance is the Hamming distance of the culture vectors """
    return sum(e1!=e2 for e1, e2 in zip(c1, c2))

"""
 • Agents may avoid other agents when the expected gain from moving to their
   spot would be reduced due to their presence (different culture and thus
   competition instead of cooperation)

4.9 Collectives
===============
 • Groups of agents with similar culture on the same patch form temporary
   groups to collaborate for the exploitation of resources. The efficiency of
   the group is merely an emergent property of the individual Agent sizes.
   Adaptation of culture vectors is a function of these groups.
   
   # NCP: you are just adding up the agent sizes? or something fancier depending on the cultural distance? And then adaptation of culture vectors means that cultures become more similar? how?

4.10 Observation
================
 • The following statistics are aggregated each time step.
"""

def observation(
        state: State,
        to: IO[str]=sys.stdout,
        extensive: IO[str]=open("log", "w")) -> None:
    # Number of families (agents)
    report = {}
    extreport: Dict[str, Any] = {}
    report["t"] = state.t
    report["Number of families"] = sum([len(families) for families in state.families.values()])
    if len(state.families) == 0:
        raise StopIteration
    report["Total population count"] = sum(
        [family.effective_size
         for fs in state.families.values()
         for family in fs])
    report["Median stored resources"] = numpy.median(
        [family.stored_resources
         for fs in state.families.values()
         for family in fs])
    extreport["Families"] = {
        family.descendence: (family.effective_size, family.location_history[0], ''.join('01'[x] for x in family.culture))
        for fs in state.families.values()
        for family in fs}
    extreport["Resources"] = [
        s.grid.patches[mij].resources for mij in numpy.ndindex(*coordinates.shape[:-1])]

    print(report, file=to)
    print(json.dumps(extreport, default=serialize), file=extensive)

# 5. Initialization
# =================
# In addition to describing the initialization, we list the parameters of the model
# here. Parameters are read from arguments specified on the command line, with
# the following default values. The sources for the default values are given.


def patch_from_grid_index(index: Index) -> Patch:
    longitude, latitude = coordinates[index]
    data = get_data(longitude, latitude)
    resources = (
        binford2001constructing.TERMD2(**data) * # Carrying capacity /km²
        gavin2017processbased.area / # Area in m²
        1_000_000 * # km²/m²
        params.time_step_energy_use # Individual energy needs
    )
    return Patch(resources, resources)


def parse_args(args: Sequence[str]) -> Tuple[halfyears, kcal]:
    parser = argparse.ArgumentParser(description="Run dispersal model")
    parser.add_argument(
        "--n-steps", type=halfyears, default=30_000,
        help="The number of half-year steps to run the simulation for. The "
        "default is 30000 half-years, because the current scientific "
        "consensus is that the settlement of the Americas began some 15000 "
        "years BP.") # Cite: 
    parser.add_argument(
        "--daily-energy", type=kcal, default=2263,
        help="Energy consumption per adult per day. According to Pontzer et "
        "al. (2012), the mean daily total energy expenditure among Hadza was "
        "2263 kcal (mean of men and women). Smith & Smith (2003) work with a "
        "staple diet containing 2390 kcal/day.")
    parser.add_argument(
        "--payoff-standarddeviation", type=int, default=0.1,
        help="The standard deviation of the foraging contribution distribution, relative to the expected foraging contribution of an individual.")
    parser.add_argument(
        "--cooperation-gain", type=int, default=0.5,
        help="The exponent of the additional efficiency of a group working together. If, eg., cooperation_gain==0.3, then two individuals working together contribute as much as 4 working separately, 3 as 7.2, 4 as 11, 5 as 15 etc.")
    parser.add_argument(
        "--storage-loss", type=float, default=0.33,
        help="The proportion of stored resources lost per time step to "
        "various random effects, such as pests, rot, spoilage, or leaving "
        "them behind when migrating. Morgan (2012) pulls a number of 33% per "
        "year (focussing on the winter season when it matters) out of thin air.")
    parser.add_argument(
        "--culture-mutation-rate", type=float, default=1e-2,
        help="The probability per half-year that one aspect of culture changes")
    parser.add_argument(
        "--cooperation_threshold", type=float, default=6,
        help="The minimum cultural distance where cooperation breaks down")
    parser.add_argument(
        "--attention-probability", type=float, default=0.2,
        help="Probability to know about the state of some patch")
    parser.add_argument(
        "--resource-recovery", type=float, default=0.2,
        help="The growth rate of a path's resources over half a year")
    parser.add_argument(
        "--accessible-resources", type=float, default=0.3,
        help="The proportion of resources that are accessible to foraging."
        # cf. Crema (2015)
    )

    global params
    params = parser.parse_args(args)
    params.time_step_energy_use = params.daily_energy * 365.24219 / 2

    return params.n_steps, params.daily_energy

def initialization() -> State:
    @attr.s
    class SpecificCells (Cells):
        neighbor_cache: Dict[Tuple[Index, meters], Sequence[Index]] = attr.ib(factory=dict)
        @staticmethod
        def neighbors(mij: Index) -> List[Index]:
            cs = neighbors(mij)
            return [c for c in cs
                    if 0 <= c[1] < coordinates.shape[1]
                    if 0 <= c[2] < coordinates.shape[2]]

        def neighbors_within_distance(self, mij: Index, d: meters) -> Sequence[Index]:
            try:
                return self.neighbor_cache[mij, d]
            except KeyError:
                self.neighbor_cache[mij, d] = list(self._neighbors_within_distance(mij, d))
                return self.neighbor_cache[mij, d]

        def _neighbors_within_distance(self, mij: Index, d: meters) -> Iterable[Index]:
            """A generator of all cells within d meters of mij.

            Yield mij back as first item of the generator.
            """
            visited = set()
            to_be_visited = self.neighbors(mij)
            yield mij
            c = coordinates[mij]
            while to_be_visited:
                n = to_be_visited.pop()
                visited.add(n)
                if numpy.asarray(GEODESIC.inverse(c, coordinates[n])[:, 0]) <= d:
                    yield n
                    for nn in self.neighbors(n):
                        if nn in visited:
                            continue
                        elif nn in to_be_visited:
                            continue
                        else:
                            to_be_visited.append(nn)

    grid = SpecificCells(patches=OnDemandDict(patch_from_grid_index))

    # If we want all cells initialized at simulation start:
    for mij in numpy.ndindex(*coordinates.shape[:-1]):
        grid.patches[mij]

    return State(grid=grid, families=DefaultDict[Index, List[Family]](
        list, {
        (0, 28, 101): [Family(
            descendence="F",
            culture=[True] * 15,
            location_history=[(0, 28, 101)],
            stored_resources=16000000)],
        (0, 50, 52): [Family(
            descendence="A",
            culture=[False] * 15,
            location_history=[(0, 50, 52)],
            stored_resources=16000000)],
        # (0, 218, 521): Family(
        #     descendence="M",
        #     location=(0, 218, 521),# Start around Manaus
        #     culture=(2,2,2,2,2,2,2,2,2,2,2),
        #     stored_resources=16000000),
    }))

# 6. Input Data
# =============

# This model does not currently use input data to represent time-varying
# processes. At a later stage, the inclusion of paleoclimate data for the
# Americas is intended as input data.

# 7. Submodels
# ============
#

def resources_at_season_end(resources: kcal, size: int) -> kcal:
    """7.1 Resource use model

    Use up a family's resources, and modify the remainder due to storage loss.

    Every adult consumes `daily_energy` kcal of food per day, for the period of
    one time step, i.e. half a year.

    """
    resources_after = resources - (
        size * params.time_step_energy_use)
    if resources_after > 0:
        resources_after = (1 - params.storage_loss)
    return resources_after


def extract_resources(patch: Patch, group: CooperativeGroup, total_labor_here: int) -> kcal:
    labor = sum([family.effective_size
                 for family in group])
    resources_extracted = resources_from_patch(
        patch, labor, total_labor_here - labor)
    for family in group:
        family.stored_resources += resources_extracted * family.effective_size / labor
    return resources_extracted


def use_resources_and_maybe_shrink(family: Family) -> None:
    resources, size = family.stored_resources, family.effective_size
    while resources_at_season_end(resources, size) < 0 and size > 0:
        size -= 1
        family.plenty_seasons_since_last_child = 0
    family.effective_size = size
    family.stored_resources = resources_at_season_end(
        family.stored_resources, family.effective_size)


def maybe_grow(family: Family) -> None:
    if family.plenty_seasons_since_last_child > 1:
        family.effective_size += 1
        family.plenty_seasons_since_last_child = 0
    else:
        family.plenty_seasons_since_last_child += 1


def is_moribund(family: Family) -> bool:
    if family.effective_size < 2:
        return True
    else:
        return False


def movement_bookkeeping(family: Family, destination: Index, state: State) -> None:
    if destination == family.location_history[0]:
        return
    try:
        family.location_history.remove(destination)
    except ValueError:
        pass
    try:
        state.families[family.location_history[0]].remove(family)
    except ValueError:
        pass
    family.location_history.insert(0, destination)
    state.families[family.location_history[0]].append(family)


def maybe_procreate(family: Family) -> Optional[Family]:
    if family.effective_size < 10:
        return None
    else:
        family.number_offspring += 1
        family.effective_size -= 2
        # These two individuals form the new family
        return Family(
            effective_size=2,
            descendence="{:s}:{:d}".format(family.descendence, family.number_offspring),
            location_history=family.location_history[:],
            culture=family.culture[:])


def decide_on_moving(
        family: Family,
        current_patch: Patch,
        known_destinations: Iterator[Tuple[Index, Patch, int, int]]) -> Index:
    target, patch, cooperators, competitors = next(known_destinations)
    assert patch == current_patch
    current_gain: kcal = resources_from_patch(
        current_patch, cooperators, competitors) * family.effective_size / cooperators
    max_gain = current_gain
    for coords, patch, cooperators, competitors in known_destinations:
        expected_gain = resources_from_patch(
                patch, family.effective_size + cooperators, competitors) * (
                    family.effective_size / (family.effective_size + cooperators))
        if expected_gain > max_gain and expected_gain > current_gain + params.time_step_energy_use:
            target = coords
            max_gain = expected_gain
    return coords


def cooperate(families: Sequence[Family]) -> Tuple[Sequence[CooperativeGroup], int]:
    cooperative_groups: List[CooperativeGroup] = []
    sum_labor = 0
    for family in families:
        sum_labor += family.effective_size
        for group in cooperative_groups:
            for other_family in group:
                if cultural_distance(
                        family.culture, other_family.culture) > params.cooperation_threshold:
                    break
            else:
                group.append(family)
                break
        else:
            cooperative_groups.append(CooperativeGroup([family]))
    for group in cooperative_groups:
        group.efficiency = 1/len(families)
    return cooperative_groups, sum_labor


def effective_labour_after_cooperation(labor: int) -> float:
    """Effective total labor contribution of a group of cooperators"""
    # From crema2014simulation, adapted
    return labor * (1 + (labor - 1) ** params.cooperation_gain)


def resources_from_patch(
        patch: Patch,
        labor: int,
        others_labor: int) -> kcal:
    # From crema2014simulation
    my_relative_returns = numpy.maximum(numpy.random.normal(
        loc=params.time_step_energy_use * effective_labour_after_cooperation(labor),
        scale=params.payoff_standarddeviation * params.time_step_energy_use / labor ** 0.5),
                                     0)
    if others_labor:
        others_relative_returns = numpy.maximum(numpy.random.normal(
            loc=params.time_step_energy_use * effective_labour_after_cooperation(others_labor),
            scale=params.payoff_standarddeviation * params.time_step_energy_use / others_labor ** 0.5),
                                                0)
    else:
        others_relative_returns = 0
    return (my_relative_returns) / (
        my_relative_returns + others_relative_returns) * numpy.minimum(
            my_relative_returns + others_relative_returns,
            patch.resources * params.accessible_resources)

def mutate_culture(family: Family) -> None:
    if family.seasons_until_next_mutation <= 0:
        if family.seasons_until_next_mutation == 0:
            i = numpy.random.randint(len(family.culture))
            family.culture[i] = not family.culture[i]
        family.seasons_until_next_mutation = numpy.random.geometric(params.culture_mutation_rate)
    else:
        family.seasons_until_next_mutation -= 1


def adjust_culture(cooperating_families: CooperativeGroup) -> None:
    n = len(cooperating_families)
    for family in cooperating_families:
        mutate_culture(family)
    if n <= 1:
        return
    def squared_p(k: int) -> float:
        return k ** 2 / (k ** 2 + (n - k) ** 2)
    culture = [family.culture for family in cooperating_families]
    target = [numpy.random.random() < squared_p(sum(c)) for c in zip(*culture)]
    for family in cooperating_families:
        family.culture[:] = target[:]


def exploit(patch: Patch, resource_reduction: kcal) -> None:
    patch.resources -= resource_reduction
    assert patch.resources > 0,  "Patch was extremely over-exploited"
    # They should be bigger than 0, but there may be rounding errors


def recover(patch: Patch) -> None:
    if patch.resources < patch.max_resources - 1:
        patch.resources += (
            patch.resources *
            params.resource_recovery *
            (1 - patch.resources / patch.max_resources))

# Run the simulation
if __name__ == "__main__":
    parse_args(["--n", "30000"])
    s = initialization()
    simulate(s, params.n_steps)

sources = """
Bibliography
============

Grimm, Volker & Berger, Uta & Bastiansen, Finn & Eliassen, Sigrunn & Ginot,
    Vincent & Giske, Jarl & Goss-Custard, John et al. 2006. A standard protocol
    for describing individual-based and agent-based models. Ecological
    Modelling 198(1). 115–126. (doi:10.1016/j.ecolmodel.2006.04.023)

Grimm, Volker & Berger, Uta & DeAngelis, Donald L. & Polhill, J. Gary & Giske,
    Jarl & Railsback, Steven F. 2010. The ODD protocol: A review and first
    update. Ecological Modelling 221(23). 2760–2768.
    (doi:10.1016/j.ecolmodel.2010.08.019)

""".split("\n\n")[1:]
